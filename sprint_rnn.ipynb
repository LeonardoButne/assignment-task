{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sprint: Evolutionary RNN Methodologies\n",
        "\n",
        "## 1. About this Sprint\n",
        "**Purpose of Sprint**\n",
        "- Understanding Evolutionary RNN Methodologies\n",
        "- Read the document comprehensively\n",
        "\n",
        "**How to learn**\n",
        "- You will learn while operating the RNN-related layers provided in Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Recurrent layer by Keras\n",
        "Keras provides multiple recurrent layers and related classes. In this Sprint, we will explore them and aim to explain their roles.\n",
        "\n",
        "### References:\n",
        "- [Recurrent Layers - Keras Documentation](https://keras.io/api/layers/recurrent_layers/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem 1: Implementation of various methods\n",
        "Keras offers four different Recurrent layers. Except for `SimpleRNN`, the others are **gated recurrent neural networks**.\n",
        "\n",
        "- SimpleRNN\n",
        "- GRU\n",
        "- LSTM\n",
        "- ConvLSTM2D\n",
        "\n",
        "Tasks:\n",
        "- Implement and compare SimpleRNN, GRU, and LSTM on a dataset (e.g., IMDB sentiment analysis).\n",
        "- Compare their accuracy.\n",
        "- Adjust hyperparameters such as number of nodes and epochs for feasibility.\n",
        "\n",
        "### References:\n",
        "- [LSTM Sample Code](https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/imdb_lstm.py)\n",
        "- [ConvLSTM2D Sample Code](https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/conv_lstm.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Simple LSTM on IMDB dataset\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN, GRU\n",
        "\n",
        "max_features = 10000  # number of words to consider\n",
        "maxlen = 500          # cut texts after this number of words\n",
        "batch_size = 32\n",
        "\n",
        "print(\"Loading data...\")\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), \"train sequences\")\n",
        "print(len(x_test), \"test sequences\")\n",
        "\n",
        "print(\"Pad sequences (samples x time)...\")\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(64))  # Try replacing with SimpleRNN or GRU\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=batch_size)\n",
        "\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"Test score:\", score)\n",
        "print(\"Test accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2 (Advanced Assignment): Comparison Between Multiple Datasets\n",
        "Experiment with other datasets provided in Keras.\n",
        "\n",
        "For example, use the **Reuters Newswire Topics Classification** dataset to compare performance between SimpleRNN, GRU, and LSTM.\n",
        "\n",
        "- [Datasets - Keras Documentation](https://keras.io/api/datasets/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3: Explanation of other classes\n",
        "The Keras documentation lists other related classes. Some of them include:\n",
        "\n",
        "- **RNN**: Base class for recurrent layers.\n",
        "- **SimpleRNNCell**: The fundamental building block for `SimpleRNN`.\n",
        "- **GRUCell**: The basic unit for GRU networks.\n",
        "- **LSTMCell**: The basic unit for LSTM networks.\n",
        "- **StackedRNNCells**: Allows stacking multiple RNN cells.\n",
        "- **CuDNNGRU**: Optimized GRU for NVIDIA GPUs.\n",
        "- **CuDNNLSTM**: Optimized LSTM for NVIDIA GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "1. About this Sprint\n",
        "2. Recurrent layer by Keras\n",
        "3. Problem 1: Implementation of various methods\n",
        "4. Question 2: Comparison Between Multiple Datasets\n",
        "5. Question 3: Explanation of other classes\n",
        "\n",
        "---\n",
        "### Recommended Version of Assignment\n",
        "- Ruby 2.6.5\n",
        "- Ruby on Rails 5.2.3\n",
        "- Python 3.7.x\n",
        "- Keras 2.2.x\n",
        "- TensorFlow 1.14.x / 2.0\n",
        "- PyTorch 1.2.x"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.9.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
